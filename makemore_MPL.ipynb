{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2Og77J+FLQeCSYbHgACLi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyaoka/-makemore-/blob/main/makemore_MPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A neural probabilistic language model\n",
        "\n"
      ],
      "metadata": {
        "id": "m6q_ERkYeDTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mlp - multilayer perceptron"
      ],
      "metadata": {
        "id": "KbWCCtNkHD3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "iCbgRqDyI2rI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVzq1zRUKkUS",
        "outputId": "ae4a6886-2919-4c6f-ed89-0fc1d8d9c909"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-09 07:27:34--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.1’\n",
            "\n",
            "\rnames.txt.1           0%[                    ]       0  --.-KB/s               \rnames.txt.1         100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-06-09 07:27:34 (11.7 MB/s) - ‘names.txt.1’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words =  open('names.txt','r').read().splitlines()"
      ],
      "metadata": {
        "id": "e16aXIMzKYqa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJxlccMmKri1",
        "outputId": "2598d941-681a-4107-c460-bcf83dda33ff"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words) # total vocabulary "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsNY6m1DKvL8",
        "outputId": "00609b61-d23e-40d3-fbbc-d5bde1e3fda1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The set() function is used to remove duplicate characters, ensuring each character appears only once.\n",
        "- list() is then used to convert the set back into a list.'        \n",
        "sorted() is applied to sort the characters in alphabetical order."
      ],
      "metadata": {
        "id": "bCptAY5758XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.']=0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HK9DqC7K1ps",
        "outputId": "f60385f1-2e6e-453f-e3e0-bb65fbabafd1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the dataset "
      ],
      "metadata": {
        "id": "zRFQL3bvL7JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "block_size = 3  # how many chars serve as input for prediction of next word \n",
        "X ,Y =[],[]         # Initialize empty lists for input-output pairs.\n",
        "\n",
        "for w in words[:5]: # iterate over words (first 5)\n",
        "\n",
        "  print(w)              # print word \n",
        "  context = [0]*block_size      # initialize list with name context .\n",
        "                                # This means that initially, the context list\n",
        "                                # is filled with block_size number of zeros\n",
        "                                # block_size =3 , context = [0,0,0]\n",
        "  for ch in w + '.':        #Iterate over each character in the current word,\n",
        "    ix= stoi[ch]            # convert the character to its corresponding index \n",
        "    X.append(context)        # Append the current context to the input list \"X\n",
        "    Y.append(ix)              # append current index to output list Y  \n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])# Append the current context to the input list \"X\n",
        "    context = context[1:] + [ix]    # Update the context by removing the first element and adding the current index\n",
        "  \n",
        "X = torch.tensor(X)  # Convert the input list \"X\" to a PyTorch tensor\n",
        "Y = torch.tensor(Y)  # Convert the output list \"Y\" to a PyTorch tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zviIYiOxMGD7",
        "outputId": "ce02205a-1ef8-4ae7-cbed-71530d904cd9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape , X.dtype , Y.shape , Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe3OHFQmRj3M",
        "outputId": "6a46a87b-1d2f-4730-b48e-8b6eb963a251"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X # training examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXUozNfWRvmb",
        "outputId": "fa5e1dde-cf1f-46b8-a07a-127d25bdc186"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0,  5],\n",
              "        [ 0,  5, 13],\n",
              "        [ 5, 13, 13],\n",
              "        [13, 13,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 15],\n",
              "        [ 0, 15, 12],\n",
              "        [15, 12,  9],\n",
              "        [12,  9, 22],\n",
              "        [ 9, 22,  9],\n",
              "        [22,  9,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  1],\n",
              "        [ 0,  1, 22],\n",
              "        [ 1, 22,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  9],\n",
              "        [ 0,  9, 19],\n",
              "        [ 9, 19,  1],\n",
              "        [19,  1,  2],\n",
              "        [ 1,  2,  5],\n",
              "        [ 2,  5, 12],\n",
              "        [ 5, 12, 12],\n",
              "        [12, 12,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 19],\n",
              "        [ 0, 19, 15],\n",
              "        [19, 15, 16],\n",
              "        [15, 16,  8],\n",
              "        [16,  8,  9],\n",
              "        [ 8,  9,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y # labels  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvm050NhR20Q",
        "outputId": "972d9a5f-e0ce-4997-8a7c-f194528465e9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2))"
      ],
      "metadata": {
        "id": "xlTduvOmR7En"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfWXzm7nRzrx",
        "outputId": "1e510e37-2ca4-41a4-f3d0-b2fe4630c300"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0176, -2.9017],\n",
              "        [ 0.7098, -0.1776],\n",
              "        [ 1.0133, -0.8292],\n",
              "        [-1.0780,  1.0127],\n",
              "        [-0.4650,  0.6155],\n",
              "        [-0.8566, -0.2315],\n",
              "        [-0.3087, -0.3012],\n",
              "        [-0.4853, -1.4070],\n",
              "        [ 0.1790,  0.5858],\n",
              "        [-0.5229,  0.5162],\n",
              "        [ 1.3855, -0.0806],\n",
              "        [ 0.3560, -1.2736],\n",
              "        [ 0.9760,  0.9649],\n",
              "        [-0.3318, -1.7092],\n",
              "        [ 0.2770, -0.1510],\n",
              "        [ 0.2807,  1.1361],\n",
              "        [-1.0566,  3.0255],\n",
              "        [ 0.1923,  0.6397],\n",
              "        [-0.4348,  0.0981],\n",
              "        [ 0.9979, -1.0869],\n",
              "        [ 1.4081, -0.1886],\n",
              "        [ 0.4054,  0.9347],\n",
              "        [-1.4098,  0.6160],\n",
              "        [-1.7200, -0.6754],\n",
              "        [ 1.8951, -1.6460],\n",
              "        [-0.3827,  0.3284],\n",
              "        [-0.1145, -0.7506]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(torch.tensor(5),num_classes=27)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmrma_ZbSpvQ",
        "outputId": "e1a3ce40-960f-481c-ed14-8379526a5905"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take one hot vect and mulitply by C\n",
        "# one_hot encoding by default is int . so need to convert to float.\n",
        "F.one_hot(torch.tensor(5),num_classes=27).float() @ C\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRRwuPhrS_oM",
        "outputId": "86c05f53-e297-4f89-9258-1b866c764ac7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8566, -0.2315])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpLGsg0OTcnX",
        "outputId": "64693978-f5e5-4808-9206-82f4eeaed95d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8566, -0.2315])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- both output of above lines are same  ."
      ],
      "metadata": {
        "id": "y1nZkeFST5or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pytorch indexing -- learn"
      ],
      "metadata": {
        "id": "zWxepH1NWYRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "id": "1Rp7ORhRaHAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5c7ef0-fbe9-4794-df81-62b5823ff4eb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights\n",
        "W1 = torch.randn((6,100))\n",
        "# bias\n",
        "b1 = torch.randn(100)   "
      ],
      "metadata": {
        "id": "xPTJTU9qZ7Mv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([emb[:,0,:],emb[:,1,:],emb[:,2,:]],1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWigcn47csaA",
        "outputId": "238b209e-8c2c-4fb5-f1b4-cd9380ab2a37"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017, -0.8566, -0.2315],\n",
              "        [ 1.0176, -2.9017, -0.8566, -0.2315, -0.3318, -1.7092],\n",
              "        [-0.8566, -0.2315, -0.3318, -1.7092, -0.3318, -1.7092],\n",
              "        [-0.3318, -1.7092, -0.3318, -1.7092,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.2807,  1.1361],\n",
              "        [ 1.0176, -2.9017,  0.2807,  1.1361,  0.9760,  0.9649],\n",
              "        [ 0.2807,  1.1361,  0.9760,  0.9649, -0.5229,  0.5162],\n",
              "        [ 0.9760,  0.9649, -0.5229,  0.5162, -1.4098,  0.6160],\n",
              "        [-0.5229,  0.5162, -1.4098,  0.6160, -0.5229,  0.5162],\n",
              "        [-1.4098,  0.6160, -0.5229,  0.5162,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  0.7098, -0.1776, -1.4098,  0.6160],\n",
              "        [ 0.7098, -0.1776, -1.4098,  0.6160,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017, -0.5229,  0.5162],\n",
              "        [ 1.0176, -2.9017, -0.5229,  0.5162,  0.9979, -1.0869],\n",
              "        [-0.5229,  0.5162,  0.9979, -1.0869,  0.7098, -0.1776],\n",
              "        [ 0.9979, -1.0869,  0.7098, -0.1776,  1.0133, -0.8292],\n",
              "        [ 0.7098, -0.1776,  1.0133, -0.8292, -0.8566, -0.2315],\n",
              "        [ 1.0133, -0.8292, -0.8566, -0.2315,  0.9760,  0.9649],\n",
              "        [-0.8566, -0.2315,  0.9760,  0.9649,  0.9760,  0.9649],\n",
              "        [ 0.9760,  0.9649,  0.9760,  0.9649,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.9979, -1.0869],\n",
              "        [ 1.0176, -2.9017,  0.9979, -1.0869,  0.2807,  1.1361],\n",
              "        [ 0.9979, -1.0869,  0.2807,  1.1361, -1.0566,  3.0255],\n",
              "        [ 0.2807,  1.1361, -1.0566,  3.0255,  0.1790,  0.5858],\n",
              "        [-1.0566,  3.0255,  0.1790,  0.5858, -0.5229,  0.5162],\n",
              "        [ 0.1790,  0.5858, -0.5229,  0.5162,  0.7098, -0.1776]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **generalization of above code**"
      ],
      "metadata": {
        "id": "UhK_TWbvgQ5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(torch.unbind(emb,1),1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZwnvByHfzXH",
        "outputId": "f488eb6b-89bd-4225-8214-28b888c133fb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017, -0.8566, -0.2315],\n",
              "        [ 1.0176, -2.9017, -0.8566, -0.2315, -0.3318, -1.7092],\n",
              "        [-0.8566, -0.2315, -0.3318, -1.7092, -0.3318, -1.7092],\n",
              "        [-0.3318, -1.7092, -0.3318, -1.7092,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.2807,  1.1361],\n",
              "        [ 1.0176, -2.9017,  0.2807,  1.1361,  0.9760,  0.9649],\n",
              "        [ 0.2807,  1.1361,  0.9760,  0.9649, -0.5229,  0.5162],\n",
              "        [ 0.9760,  0.9649, -0.5229,  0.5162, -1.4098,  0.6160],\n",
              "        [-0.5229,  0.5162, -1.4098,  0.6160, -0.5229,  0.5162],\n",
              "        [-1.4098,  0.6160, -0.5229,  0.5162,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  0.7098, -0.1776, -1.4098,  0.6160],\n",
              "        [ 0.7098, -0.1776, -1.4098,  0.6160,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017, -0.5229,  0.5162],\n",
              "        [ 1.0176, -2.9017, -0.5229,  0.5162,  0.9979, -1.0869],\n",
              "        [-0.5229,  0.5162,  0.9979, -1.0869,  0.7098, -0.1776],\n",
              "        [ 0.9979, -1.0869,  0.7098, -0.1776,  1.0133, -0.8292],\n",
              "        [ 0.7098, -0.1776,  1.0133, -0.8292, -0.8566, -0.2315],\n",
              "        [ 1.0133, -0.8292, -0.8566, -0.2315,  0.9760,  0.9649],\n",
              "        [-0.8566, -0.2315,  0.9760,  0.9649,  0.9760,  0.9649],\n",
              "        [ 0.9760,  0.9649,  0.9760,  0.9649,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.9979, -1.0869],\n",
              "        [ 1.0176, -2.9017,  0.9979, -1.0869,  0.2807,  1.1361],\n",
              "        [ 0.9979, -1.0869,  0.2807,  1.1361, -1.0566,  3.0255],\n",
              "        [ 0.2807,  1.1361, -1.0566,  3.0255,  0.1790,  0.5858],\n",
              "        [-1.0566,  3.0255,  0.1790,  0.5858, -0.5229,  0.5162],\n",
              "        [ 0.1790,  0.5858, -0.5229,  0.5162,  0.7098, -0.1776]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(18)"
      ],
      "metadata": {
        "id": "Lj-XRHYyhFFz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMxyHgA6hK0H",
        "outputId": "187a0a19-3b6f-49a2-8926-bfcfded061fd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(3,3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OVYBrKSgP__",
        "outputId": "716b6c45-c4d3-4b87-cde6-4c099c486f29"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1],\n",
              "         [ 2,  3],\n",
              "         [ 4,  5]],\n",
              "\n",
              "        [[ 6,  7],\n",
              "         [ 8,  9],\n",
              "         [10, 11]],\n",
              "\n",
              "        [[12, 13],\n",
              "         [14, 15],\n",
              "         [16, 17]]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(9,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvbduP3RhmAS",
        "outputId": "d8fe5662-facc-4021-a8d1-23caaa1836c4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 2,  3],\n",
              "        [ 4,  5],\n",
              "        [ 6,  7],\n",
              "        [ 8,  9],\n",
              "        [10, 11],\n",
              "        [12, 13],\n",
              "        [14, 15],\n",
              "        [16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- storage remains same but seen as different \n",
        "-Blog below goes in depth \n",
        "- http://blog.ezyang.com/2019/05/pytorch-internals/"
      ],
      "metadata": {
        "id": "CBl3lK7Chps6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imp**\n",
        "- **A tensor is always representated as one dim vector.**\n",
        "- **when we call view some internal attributes of view of tensor changes .**\n"
      ],
      "metadata": {
        "id": "WzDBBJEGJUvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.storage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozFsA8DjgNmc",
        "outputId": "896031d5-f049-495a-e39c-a4807435089c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0\n",
              " 1\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5\n",
              " 6\n",
              " 7\n",
              " 8\n",
              " 9\n",
              " 10\n",
              " 11\n",
              " 12\n",
              " 13\n",
              " 14\n",
              " 15\n",
              " 16\n",
              " 17\n",
              "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- more effecient way . "
      ],
      "metadata": {
        "id": "u-aldns4ihtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuA-q7HRG5WJ",
        "outputId": "36ecec21-151d-400c-aa67-9b8cb28fe664"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92laibWoE_9h",
        "outputId": "b69afc1c-c74f-4e08-8201-dd9a879d0463"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017, -0.8566, -0.2315],\n",
              "        [ 1.0176, -2.9017, -0.8566, -0.2315, -0.3318, -1.7092],\n",
              "        [-0.8566, -0.2315, -0.3318, -1.7092, -0.3318, -1.7092],\n",
              "        [-0.3318, -1.7092, -0.3318, -1.7092,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.2807,  1.1361],\n",
              "        [ 1.0176, -2.9017,  0.2807,  1.1361,  0.9760,  0.9649],\n",
              "        [ 0.2807,  1.1361,  0.9760,  0.9649, -0.5229,  0.5162],\n",
              "        [ 0.9760,  0.9649, -0.5229,  0.5162, -1.4098,  0.6160],\n",
              "        [-0.5229,  0.5162, -1.4098,  0.6160, -0.5229,  0.5162],\n",
              "        [-1.4098,  0.6160, -0.5229,  0.5162,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  0.7098, -0.1776, -1.4098,  0.6160],\n",
              "        [ 0.7098, -0.1776, -1.4098,  0.6160,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017, -0.5229,  0.5162],\n",
              "        [ 1.0176, -2.9017, -0.5229,  0.5162,  0.9979, -1.0869],\n",
              "        [-0.5229,  0.5162,  0.9979, -1.0869,  0.7098, -0.1776],\n",
              "        [ 0.9979, -1.0869,  0.7098, -0.1776,  1.0133, -0.8292],\n",
              "        [ 0.7098, -0.1776,  1.0133, -0.8292, -0.8566, -0.2315],\n",
              "        [ 1.0133, -0.8292, -0.8566, -0.2315,  0.9760,  0.9649],\n",
              "        [-0.8566, -0.2315,  0.9760,  0.9649,  0.9760,  0.9649],\n",
              "        [ 0.9760,  0.9649,  0.9760,  0.9649,  0.7098, -0.1776],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  1.0176, -2.9017],\n",
              "        [ 1.0176, -2.9017,  1.0176, -2.9017,  0.9979, -1.0869],\n",
              "        [ 1.0176, -2.9017,  0.9979, -1.0869,  0.2807,  1.1361],\n",
              "        [ 0.9979, -1.0869,  0.2807,  1.1361, -1.0566,  3.0255],\n",
              "        [ 0.2807,  1.1361, -1.0566,  3.0255,  0.1790,  0.5858],\n",
              "        [-1.0566,  3.0255,  0.1790,  0.5858, -0.5229,  0.5162],\n",
              "        [ 0.1790,  0.5858, -0.5229,  0.5162,  0.7098, -0.1776]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6) == torch.cat(torch.unbind(emb,1),1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j7A7rY8hQvx",
        "outputId": "f1ef8b1c-cee3-4d9c-998a-7f520aa9289b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h= torch.tan(emb.view(-1,6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "iaUy57qjj1Of"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olZE7XLdlNDK",
        "outputId": "fe999584-7f9c-48bc-9ec0-a2723f3b5bae"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.8995e-01,  4.1444e+03,  1.2405e+00,  ...,  8.0510e+00,\n",
              "         -6.6985e-01,  5.7273e-01],\n",
              "        [-3.1463e-01,  3.2693e+00,  4.8427e-01,  ...,  1.7067e-01,\n",
              "          1.2643e+00,  5.1718e+00],\n",
              "        [-4.1071e+00,  6.8273e-01, -1.6180e+00,  ..., -2.3189e+00,\n",
              "          4.0507e-01, -1.2470e+00],\n",
              "        ...,\n",
              "        [ 1.5295e-01,  1.8306e-02,  2.6965e-01,  ...,  1.7537e+00,\n",
              "         -5.1406e-02, -8.8990e-01],\n",
              "        [-1.0324e+00, -8.7157e-01, -4.2512e-01,  ..., -7.9481e+01,\n",
              "         -5.3583e+00, -7.6421e-01],\n",
              "        [-2.5266e+00,  6.9549e+00,  1.5301e+00,  ..., -4.0386e+00,\n",
              "         -1.3271e-01, -2.4449e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- inputs are 100 \n",
        "- outputs are 27 ( possible category)\n",
        "- bias are 27"
      ],
      "metadata": {
        "id": "2ys9x1GQEoZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn((100,27)) \n",
        "\n",
        "b2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "-bs3Be6IlVlA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- logits = output \n",
        "- "
      ],
      "metadata": {
        "id": "3sa9yQ6-EzF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 +b2"
      ],
      "metadata": {
        "id": "YnqArQgwlOEI"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVy8BCrXlpmp",
        "outputId": "c1d6db7a-c636-4a25-b3ee-1bf89545335c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()"
      ],
      "metadata": {
        "id": "2A87VcLvlqsP"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalised\n",
        "prob = counts / counts.sum(1,keepdims=True)"
      ],
      "metadata": {
        "id": "RY5TmfK8lwv0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = -prob[torch.arange(32),Y].log().mean()"
      ],
      "metadata": {
        "id": "H29njsbzl6zC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(logits,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiID0Zaozoe",
        "outputId": "9b817ff1-10b6-4825-c173-d71042d6f2d3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1443.6138)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full neural network  neural net "
      ],
      "metadata": {
        "id": "mO37afRoo-OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dataset\n",
        "- X - input is (32,3)(3 words )\n",
        "- Y -  labels (32)(expected word)\n",
        "\n"
      ],
      "metadata": {
        "id": "XNUWLGR7FJKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape , Y.shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQszzUJxFEqK",
        "outputId": "fbdeecd0-f872-47ba-d592-d477a82eca6c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. g - This will ensure that the random numbers generated by the torch.randn functions are reproducible.\n",
        "2. This line creates a tensor C of shape (27, 10) and fills it with random numbers from a normal distribution with mean 0 and variance 1. \n",
        "\n",
        "3. w1,w2,b1,b2, weights and biases.\n",
        "\n",
        "4. parameters : This line creates a list parameters containing the tensors C, W1, b1, W2, and b2. This list will be used to train the neural network."
      ],
      "metadata": {
        "id": "Q8bAy4pPGGDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n"
      ],
      "metadata": {
        "id": "HDqMG4_9FkZ6"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = [C,W1,b1,W2 , b2]\n",
        "for p in parameters:\n",
        "  p.requires_grad=True"
      ],
      "metadata": {
        "id": "VgSE6WWRZzCe"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "for _ in range(10):\n",
        "  emb = C[X] # (32, 3, 2)\n",
        "  h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "\n",
        "  #backward pass\n",
        "\n",
        "  for p in parameters:\n",
        "     p.grad = None\n",
        "  loss.backward()\n",
        "  # update \n",
        "  for p in parameters:\n",
        "    p.data += -0.1 *p.grad\n"
      ],
      "metadata": {
        "id": "9ALQexomq5XS"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wStHJ4JYA4oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training split , dev/validation split , test split\n",
        "# 80% ,  10% , 10%"
      ],
      "metadata": {
        "id": "bdn9yU9meQIz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKvevl4zebn5"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}