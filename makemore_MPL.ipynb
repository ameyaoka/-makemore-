{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGIeDq55YesSBb44GZPDSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyaoka/-makemore-/blob/main/makemore_MPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A neural probabilistic language model\n",
        "\n"
      ],
      "metadata": {
        "id": "m6q_ERkYeDTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mlp - multilayer perceptron"
      ],
      "metadata": {
        "id": "KbWCCtNkHD3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "iCbgRqDyI2rI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVzq1zRUKkUS",
        "outputId": "ad61bb0c-0498-480f-9c83-cc5fd70691e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-09 11:24:46--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-06-09 11:24:46 (7.93 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words =  open('names.txt','r').read().splitlines()"
      ],
      "metadata": {
        "id": "e16aXIMzKYqa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJxlccMmKri1",
        "outputId": "0777456e-c6d6-4196-dbde-a594708843ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words) # total vocabulary "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsNY6m1DKvL8",
        "outputId": "20901635-e0bb-4ceb-e610-ba634cec59a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The set() function is used to remove duplicate characters, ensuring each character appears only once.\n",
        "- list() is then used to convert the set back into a list.'        \n",
        "sorted() is applied to sort the characters in alphabetical order."
      ],
      "metadata": {
        "id": "bCptAY5758XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.']=0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HK9DqC7K1ps",
        "outputId": "63681bdc-c095-45c3-ecad-dfbc59ecb042"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the dataset "
      ],
      "metadata": {
        "id": "zRFQL3bvL7JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "block_size = 3  # how many chars serve as input for prediction of next word \n",
        "X ,Y =[],[]         # Initialize empty lists for input-output pairs.\n",
        "\n",
        "for w in words[:5]: # iterate over words (first 5)\n",
        "\n",
        "  print(w)              # print word \n",
        "  context = [0]*block_size      # initialize list with name context .\n",
        "                                # This means that initially, the context list\n",
        "                                # is filled with block_size number of zeros\n",
        "                                # block_size =3 , context = [0,0,0]\n",
        "  for ch in w + '.':        #Iterate over each character in the current word,\n",
        "    ix= stoi[ch]            # convert the character to its corresponding index \n",
        "    X.append(context)        # Append the current context to the input list \"X\n",
        "    Y.append(ix)              # append current index to output list Y  \n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])# Append the current context to the input list \"X\n",
        "    context = context[1:] + [ix]    # Update the context by removing the first element and adding the current index\n",
        "  \n",
        "X = torch.tensor(X)  # Convert the input list \"X\" to a PyTorch tensor\n",
        "Y = torch.tensor(Y)  # Convert the output list \"Y\" to a PyTorch tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zviIYiOxMGD7",
        "outputId": "fb2523d5-9135-42a8-967d-1c6da277eada"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape , X.dtype , Y.shape , Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe3OHFQmRj3M",
        "outputId": "6be07eef-1f96-4384-d53f-db20df3747ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X # training examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXUozNfWRvmb",
        "outputId": "d571d33b-8bfc-4e49-f4c9-b02493e1771b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0,  5],\n",
              "        [ 0,  5, 13],\n",
              "        [ 5, 13, 13],\n",
              "        [13, 13,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 15],\n",
              "        [ 0, 15, 12],\n",
              "        [15, 12,  9],\n",
              "        [12,  9, 22],\n",
              "        [ 9, 22,  9],\n",
              "        [22,  9,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  1],\n",
              "        [ 0,  1, 22],\n",
              "        [ 1, 22,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  9],\n",
              "        [ 0,  9, 19],\n",
              "        [ 9, 19,  1],\n",
              "        [19,  1,  2],\n",
              "        [ 1,  2,  5],\n",
              "        [ 2,  5, 12],\n",
              "        [ 5, 12, 12],\n",
              "        [12, 12,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 19],\n",
              "        [ 0, 19, 15],\n",
              "        [19, 15, 16],\n",
              "        [15, 16,  8],\n",
              "        [16,  8,  9],\n",
              "        [ 8,  9,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y # labels  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvm050NhR20Q",
        "outputId": "d183fc42-7dea-4ae1-f454-e5071193f165"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2))"
      ],
      "metadata": {
        "id": "xlTduvOmR7En"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfWXzm7nRzrx",
        "outputId": "509904bf-658f-4d38-86fa-abbb608590e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6600, -0.7575],\n",
              "        [-0.5145, -1.7448],\n",
              "        [-2.4160,  0.2244],\n",
              "        [ 0.8445,  1.6032],\n",
              "        [ 0.2172,  1.4561],\n",
              "        [ 0.0522,  2.0993],\n",
              "        [ 0.9500, -1.4552],\n",
              "        [-1.7349,  0.1087],\n",
              "        [ 0.1026,  0.7291],\n",
              "        [-0.0655, -1.2086],\n",
              "        [-0.0517, -1.9406],\n",
              "        [-0.3543, -0.1366],\n",
              "        [ 2.2147,  0.0240],\n",
              "        [-0.3967, -0.4748],\n",
              "        [ 1.2574, -2.2430],\n",
              "        [-1.6160,  0.3758],\n",
              "        [ 0.3545,  0.1855],\n",
              "        [-0.3210, -0.6135],\n",
              "        [ 1.6804, -0.2795],\n",
              "        [ 0.1026, -1.0732],\n",
              "        [ 0.6562, -0.0504],\n",
              "        [-0.0296, -0.7490],\n",
              "        [-0.9290, -0.4704],\n",
              "        [-0.3983,  1.1339],\n",
              "        [ 1.7175,  0.1215],\n",
              "        [-0.0433, -0.3369],\n",
              "        [-1.0604, -0.6501]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(torch.tensor(5),num_classes=27)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmrma_ZbSpvQ",
        "outputId": "ab92f2c5-138d-4de2-d9d4-577709a0e536"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take one hot vect and mulitply by C\n",
        "# one_hot encoding by default is int . so need to convert to float.\n",
        "F.one_hot(torch.tensor(5),num_classes=27).float() @ C\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRRwuPhrS_oM",
        "outputId": "5994fdcc-476c-4b13-e653-c9835cc3f977"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0522, 2.0993])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpLGsg0OTcnX",
        "outputId": "698e0aad-172f-4545-8f28-7fb112378977"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0522, 2.0993])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- both output of above lines are same  ."
      ],
      "metadata": {
        "id": "y1nZkeFST5or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pytorch indexing -- learn"
      ],
      "metadata": {
        "id": "zWxepH1NWYRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "id": "1Rp7ORhRaHAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57611b1a-bfd1-495a-9ef1-e18a33a2c0d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights\n",
        "W1 = torch.randn((6,100))\n",
        "# bias\n",
        "b1 = torch.randn(100)   "
      ],
      "metadata": {
        "id": "xPTJTU9qZ7Mv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([emb[:,0,:],emb[:,1,:],emb[:,2,:]],1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWigcn47csaA",
        "outputId": "ab2595bb-bad5-47e2-e48c-4dd807de6348"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575,  0.0522,  2.0993],\n",
              "        [-0.6600, -0.7575,  0.0522,  2.0993, -0.3967, -0.4748],\n",
              "        [ 0.0522,  2.0993, -0.3967, -0.4748, -0.3967, -0.4748],\n",
              "        [-0.3967, -0.4748, -0.3967, -0.4748, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -1.6160,  0.3758],\n",
              "        [-0.6600, -0.7575, -1.6160,  0.3758,  2.2147,  0.0240],\n",
              "        [-1.6160,  0.3758,  2.2147,  0.0240, -0.0655, -1.2086],\n",
              "        [ 2.2147,  0.0240, -0.0655, -1.2086, -0.9290, -0.4704],\n",
              "        [-0.0655, -1.2086, -0.9290, -0.4704, -0.0655, -1.2086],\n",
              "        [-0.9290, -0.4704, -0.0655, -1.2086, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.5145, -1.7448, -0.9290, -0.4704],\n",
              "        [-0.5145, -1.7448, -0.9290, -0.4704, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.0655, -1.2086],\n",
              "        [-0.6600, -0.7575, -0.0655, -1.2086,  0.1026, -1.0732],\n",
              "        [-0.0655, -1.2086,  0.1026, -1.0732, -0.5145, -1.7448],\n",
              "        [ 0.1026, -1.0732, -0.5145, -1.7448, -2.4160,  0.2244],\n",
              "        [-0.5145, -1.7448, -2.4160,  0.2244,  0.0522,  2.0993],\n",
              "        [-2.4160,  0.2244,  0.0522,  2.0993,  2.2147,  0.0240],\n",
              "        [ 0.0522,  2.0993,  2.2147,  0.0240,  2.2147,  0.0240],\n",
              "        [ 2.2147,  0.0240,  2.2147,  0.0240, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575,  0.1026, -1.0732],\n",
              "        [-0.6600, -0.7575,  0.1026, -1.0732, -1.6160,  0.3758],\n",
              "        [ 0.1026, -1.0732, -1.6160,  0.3758,  0.3545,  0.1855],\n",
              "        [-1.6160,  0.3758,  0.3545,  0.1855,  0.1026,  0.7291],\n",
              "        [ 0.3545,  0.1855,  0.1026,  0.7291, -0.0655, -1.2086],\n",
              "        [ 0.1026,  0.7291, -0.0655, -1.2086, -0.5145, -1.7448]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **generalization of above code**"
      ],
      "metadata": {
        "id": "UhK_TWbvgQ5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(torch.unbind(emb,1),1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZwnvByHfzXH",
        "outputId": "1d647846-27a6-48a8-b998-3693aa454c4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575,  0.0522,  2.0993],\n",
              "        [-0.6600, -0.7575,  0.0522,  2.0993, -0.3967, -0.4748],\n",
              "        [ 0.0522,  2.0993, -0.3967, -0.4748, -0.3967, -0.4748],\n",
              "        [-0.3967, -0.4748, -0.3967, -0.4748, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -1.6160,  0.3758],\n",
              "        [-0.6600, -0.7575, -1.6160,  0.3758,  2.2147,  0.0240],\n",
              "        [-1.6160,  0.3758,  2.2147,  0.0240, -0.0655, -1.2086],\n",
              "        [ 2.2147,  0.0240, -0.0655, -1.2086, -0.9290, -0.4704],\n",
              "        [-0.0655, -1.2086, -0.9290, -0.4704, -0.0655, -1.2086],\n",
              "        [-0.9290, -0.4704, -0.0655, -1.2086, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.5145, -1.7448, -0.9290, -0.4704],\n",
              "        [-0.5145, -1.7448, -0.9290, -0.4704, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.0655, -1.2086],\n",
              "        [-0.6600, -0.7575, -0.0655, -1.2086,  0.1026, -1.0732],\n",
              "        [-0.0655, -1.2086,  0.1026, -1.0732, -0.5145, -1.7448],\n",
              "        [ 0.1026, -1.0732, -0.5145, -1.7448, -2.4160,  0.2244],\n",
              "        [-0.5145, -1.7448, -2.4160,  0.2244,  0.0522,  2.0993],\n",
              "        [-2.4160,  0.2244,  0.0522,  2.0993,  2.2147,  0.0240],\n",
              "        [ 0.0522,  2.0993,  2.2147,  0.0240,  2.2147,  0.0240],\n",
              "        [ 2.2147,  0.0240,  2.2147,  0.0240, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575,  0.1026, -1.0732],\n",
              "        [-0.6600, -0.7575,  0.1026, -1.0732, -1.6160,  0.3758],\n",
              "        [ 0.1026, -1.0732, -1.6160,  0.3758,  0.3545,  0.1855],\n",
              "        [-1.6160,  0.3758,  0.3545,  0.1855,  0.1026,  0.7291],\n",
              "        [ 0.3545,  0.1855,  0.1026,  0.7291, -0.0655, -1.2086],\n",
              "        [ 0.1026,  0.7291, -0.0655, -1.2086, -0.5145, -1.7448]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(18)"
      ],
      "metadata": {
        "id": "Lj-XRHYyhFFz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMxyHgA6hK0H",
        "outputId": "7ca9f902-2fe9-4ad0-bd01-c2faf14af916"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(3,3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OVYBrKSgP__",
        "outputId": "c3369aff-c12d-4246-a310-10f58ef8c8da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1],\n",
              "         [ 2,  3],\n",
              "         [ 4,  5]],\n",
              "\n",
              "        [[ 6,  7],\n",
              "         [ 8,  9],\n",
              "         [10, 11]],\n",
              "\n",
              "        [[12, 13],\n",
              "         [14, 15],\n",
              "         [16, 17]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(9,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvbduP3RhmAS",
        "outputId": "03d12268-173b-4f07-f984-4060e339ae1c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 2,  3],\n",
              "        [ 4,  5],\n",
              "        [ 6,  7],\n",
              "        [ 8,  9],\n",
              "        [10, 11],\n",
              "        [12, 13],\n",
              "        [14, 15],\n",
              "        [16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- storage remains same but seen as different \n",
        "-Blog below goes in depth \n",
        "- http://blog.ezyang.com/2019/05/pytorch-internals/"
      ],
      "metadata": {
        "id": "CBl3lK7Chps6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imp**\n",
        "- **A tensor is always representated as one dim vector.**\n",
        "- **when we call view some internal attributes of view of tensor changes .**\n"
      ],
      "metadata": {
        "id": "WzDBBJEGJUvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.storage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozFsA8DjgNmc",
        "outputId": "f7c47550-66ed-4028-debc-4fb38a995fd2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-d39b3459ecdd>:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  a.storage()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0\n",
              " 1\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5\n",
              " 6\n",
              " 7\n",
              " 8\n",
              " 9\n",
              " 10\n",
              " 11\n",
              " 12\n",
              " 13\n",
              " 14\n",
              " 15\n",
              " 16\n",
              " 17\n",
              "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- more effecient way . "
      ],
      "metadata": {
        "id": "u-aldns4ihtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuA-q7HRG5WJ",
        "outputId": "e9fe8f8a-cbf5-4c9d-b9c6-eb2e1579f90a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92laibWoE_9h",
        "outputId": "477ffdf7-fefb-4cf4-d082-fb700d10ef91"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575,  0.0522,  2.0993],\n",
              "        [-0.6600, -0.7575,  0.0522,  2.0993, -0.3967, -0.4748],\n",
              "        [ 0.0522,  2.0993, -0.3967, -0.4748, -0.3967, -0.4748],\n",
              "        [-0.3967, -0.4748, -0.3967, -0.4748, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -1.6160,  0.3758],\n",
              "        [-0.6600, -0.7575, -1.6160,  0.3758,  2.2147,  0.0240],\n",
              "        [-1.6160,  0.3758,  2.2147,  0.0240, -0.0655, -1.2086],\n",
              "        [ 2.2147,  0.0240, -0.0655, -1.2086, -0.9290, -0.4704],\n",
              "        [-0.0655, -1.2086, -0.9290, -0.4704, -0.0655, -1.2086],\n",
              "        [-0.9290, -0.4704, -0.0655, -1.2086, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.5145, -1.7448, -0.9290, -0.4704],\n",
              "        [-0.5145, -1.7448, -0.9290, -0.4704, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.0655, -1.2086],\n",
              "        [-0.6600, -0.7575, -0.0655, -1.2086,  0.1026, -1.0732],\n",
              "        [-0.0655, -1.2086,  0.1026, -1.0732, -0.5145, -1.7448],\n",
              "        [ 0.1026, -1.0732, -0.5145, -1.7448, -2.4160,  0.2244],\n",
              "        [-0.5145, -1.7448, -2.4160,  0.2244,  0.0522,  2.0993],\n",
              "        [-2.4160,  0.2244,  0.0522,  2.0993,  2.2147,  0.0240],\n",
              "        [ 0.0522,  2.0993,  2.2147,  0.0240,  2.2147,  0.0240],\n",
              "        [ 2.2147,  0.0240,  2.2147,  0.0240, -0.5145, -1.7448],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575, -0.6600, -0.7575],\n",
              "        [-0.6600, -0.7575, -0.6600, -0.7575,  0.1026, -1.0732],\n",
              "        [-0.6600, -0.7575,  0.1026, -1.0732, -1.6160,  0.3758],\n",
              "        [ 0.1026, -1.0732, -1.6160,  0.3758,  0.3545,  0.1855],\n",
              "        [-1.6160,  0.3758,  0.3545,  0.1855,  0.1026,  0.7291],\n",
              "        [ 0.3545,  0.1855,  0.1026,  0.7291, -0.0655, -1.2086],\n",
              "        [ 0.1026,  0.7291, -0.0655, -1.2086, -0.5145, -1.7448]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6) == torch.cat(torch.unbind(emb,1),1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j7A7rY8hQvx",
        "outputId": "e1cb1be2-2e7a-4919-c240-dc254e23ca14"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h= torch.tan(emb.view(-1,6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "iaUy57qjj1Of"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olZE7XLdlNDK",
        "outputId": "e0c87798-438d-4155-b32e-505b50f1aa75"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2931e+00, -3.1555e-03,  2.5725e+00,  ...,  4.5177e+00,\n",
              "         -7.7827e+00,  4.1133e+00],\n",
              "        [-4.4199e-01,  4.5517e-01, -2.5949e+00,  ..., -1.1722e+00,\n",
              "          3.7941e-01, -3.9073e-01],\n",
              "        [ 5.9821e-01,  7.5502e-01,  2.5025e+00,  ..., -3.9093e-01,\n",
              "          1.0260e+00,  8.2895e-01],\n",
              "        ...,\n",
              "        [ 8.8530e-01, -1.6355e+01, -1.1575e+00,  ...,  2.4817e+00,\n",
              "          2.4210e-01,  6.2626e-01],\n",
              "        [-3.9058e-01, -7.2485e-02, -4.9877e+00,  ...,  1.0667e+00,\n",
              "          1.1304e+00,  1.3725e+01],\n",
              "        [-8.8970e-01, -9.0477e-01,  2.3066e+00,  ..., -1.7233e+01,\n",
              "         -5.7079e+01,  1.8746e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- inputs are 100 \n",
        "- outputs are 27 ( possible category)\n",
        "- bias are 27"
      ],
      "metadata": {
        "id": "2ys9x1GQEoZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn((100,27)) \n",
        "\n",
        "b2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "-bs3Be6IlVlA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- logits = output \n",
        "- "
      ],
      "metadata": {
        "id": "3sa9yQ6-EzF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 +b2"
      ],
      "metadata": {
        "id": "YnqArQgwlOEI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVy8BCrXlpmp",
        "outputId": "6e5cf480-a5e0-4cf5-cbdf-f3d19f289363"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()"
      ],
      "metadata": {
        "id": "2A87VcLvlqsP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalised\n",
        "prob = counts / counts.sum(1,keepdims=True)"
      ],
      "metadata": {
        "id": "RY5TmfK8lwv0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = -prob[torch.arange(32),Y].log().mean()"
      ],
      "metadata": {
        "id": "H29njsbzl6zC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(logits,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiID0Zaozoe",
        "outputId": "4cfe0397-1093-4e8e-af18-f4a93b1be6bc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(511.5619)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full neural network  neural net "
      ],
      "metadata": {
        "id": "mO37afRoo-OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dataset\n",
        "- X - input is (32,3)(3 words )\n",
        "- Y -  labels (32)(expected word)\n",
        "\n"
      ],
      "metadata": {
        "id": "XNUWLGR7FJKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape , Y.shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQszzUJxFEqK",
        "outputId": "68a3d728-ef6f-4569-bd2c-599116e8f5da"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. g - This will ensure that the random numbers generated by the torch.randn functions are reproducible.\n",
        "2. This line creates a tensor C of shape (27, 10) and fills it with random numbers from a normal distribution with mean 0 and variance 1. \n",
        "\n",
        "3. w1,w2,b1,b2, weights and biases.\n",
        "\n",
        "4. parameters : This line creates a list parameters containing the tensors C, W1, b1, W2, and b2. This list will be used to train the neural network."
      ],
      "metadata": {
        "id": "Q8bAy4pPGGDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 2), generator=g)\n",
        "W1 = torch.randn((6, 100), generator=g)\n",
        "b1 = torch.randn(100, generator=g)\n",
        "W2 = torch.randn((100, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n"
      ],
      "metadata": {
        "id": "HDqMG4_9FkZ6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "  p.requires_grad = True\n"
      ],
      "metadata": {
        "id": "VgSE6WWRZzCe"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  the sum function to calculate the total number of parameters in the list parameters\n",
        "\n",
        "- nelement() function is used to count the number of elements in a tensor. "
      ],
      "metadata": {
        "id": "dfEwOMOl7Sww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # number of parameters in total\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbBxVMTs69po",
        "outputId": "9477fd20-c636-46df-8c36-c7588e46a5cc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11897"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fordward pass\n",
        "for _ in range(1000):\n",
        "  emb = C[X]\n",
        "  h = torch.tanh(emb.view(-1,6) @ W1 + b1 )\n",
        "  logits = h @ W2 +b2 \n",
        "  loss = F.cross_entropy(logits ,Y)\n",
        "# backward pass\n",
        "  for  p in parameters:\n",
        "    p.grad = None \n",
        "  loss.backward()\n",
        "\n",
        "# update \n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EICujWpl-DgV",
        "outputId": "3b0e8ad8-be4f-436c-fb10-4fc840beb7b0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2556455135345459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ODwEGwmB_kNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training split , dev/validation split , test split\n",
        "# 80% ,  10% , 10%"
      ],
      "metadata": {
        "id": "bdn9yU9meQIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKvevl4zebn5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}